<!DOCTYPE html><html lang="[&quot;zh-CN&quot;,&quot;en&quot;,&quot;default&quot;]"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>CNN | 逐浪钱塘</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">CNN</h1><a id="logo" href="/.">逐浪钱塘</a><p class="description">Stay hungry, stay foolish.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">CNN</h1><div class="post-meta">Sep 18, 2018<span> | </span><span class="category"><a href="/categories/深度学习/">深度学习</a></span></div><div class="post-content"><h2 id="CNN-Convolutional-Neural-Network"><a href="#CNN-Convolutional-Neural-Network" class="headerlink" title="CNN(Convolutional Neural Network)"></a>CNN(Convolutional Neural Network)</h2><h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>这个Q的学习目标是学习实践CNN，在此之前已经有好几个同事在不同时期分享过CNN的原理、应用等。在此做一个总结，加深对其理解。CNN本质上来说是一个<strong>简化版的全连接神经网络</strong>，其特点是<strong>可以自己设计网络结构</strong>，通常用来做图像识别。</p>
<h2 id="设计思路-amp-网络结构"><a href="#设计思路-amp-网络结构" class="headerlink" title="设计思路&amp;网络结构"></a>设计思路&amp;网络结构</h2><h3 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h3><ol>
<li>做图像识别时，往往不需要侦测到全部图像，只需要其中一部分就能识别</li>
<li>同一个形状可能出现在图片的不同位置，因此只需要同样的Neural即可识别</li>
<li>图片做subsampling(抽样)得到一个缩放的图片后，依然可以识别出来</li>
</ol>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>由上述设计思路，我们得到以下网络结构：<br><img src="/images/pasted-17.png" alt="upload successful"><br><strong>注意：CNN的参数是同时训练的！</strong></p>
<ul>
<li>Convolution：会实现上述思路1，2</li>
<li>Pooling：会实现上述思路3</li>
</ul>
<h3 id="CNN-Convolution-卷积"><a href="#CNN-Convolution-卷积" class="headerlink" title="CNN-Convolution(卷积)"></a>CNN-Convolution(卷积)</h3><p>做Convolution的时候，可以理解为“拿一个小框去抠出原图的一部分来识别”。这个框比原图小，且这个框会按照一定步长覆盖整张图片。那么这个框是什么呢，其实就是filter。</p>
<p>举个🌰：</p>
<ul>
<li>有一张6x6（6x6x1）的<strong>黑白</strong>图片，如下所示。<br><img src="/images/pasted-18.png" alt="upload successful"></li>
<li>接下来我们用2个filter（2个3x3的矩阵），从图片的左上角开始按一定的步长（stride），选择同样大小的矩阵做内积（2个矩阵对应元素的乘积加和）。<ul>
<li><strong>注意1：每个filter里的数值是通过训练学习出来的，此处只为举例，假设已经知道这些数值了，然后看是怎么使用</strong></li>
<li><strong>注意2：filter的size是自己设定的，也就是说在训练中，这是一个超参数</strong></li>
<li><strong>注意3：filter的size，其实就实现了设计思路1</strong></li>
</ul>
</li>
<li>通过filter1和filter2，使用stride=1，对原图做内积后，我们得到如下结果：<ul>
<li>用fliter1做内积，可以看出在原图中，被蓝线覆盖的元素，在和filter1做内积后，得到的值最大，新的4x4的矩阵依然能反映出原图的特征。其实这点就<strong>实现了设计思路2</strong>。<br><img src="/images/pasted-24.png" alt="upload successful"></li>
<li>用filter2做内积，此时我们得到了2层（一层是通过filter1做内积的红色矩阵，另一层是通过filter2做内积得到的蓝色矩阵），那么这个有2层的4x4的矩阵，就叫做一个<strong>feature map</strong>。<br><img src="/images/pasted-26.png" alt="upload successful"></li>
</ul>
</li>
<li>通过2个filter以stride=1对原图做内积后，我们得到了一个4x4x2的feature map，可以理解为原来是一张6x6的图片，现在转换成了一张4x4x2的新图片。原来一个位置使用一个元素表示，而现在使用2个（因为有2层）。也就是说，feature map的层数，是由filter的个数决定的。</li>
</ul>
<p>上面的例子是一个黑白的图片，那如果是一张彩色图片会是怎样呢？其实跟黑白是一样的，只不过原来的6x6x1变成了6x6x3，这个3就是对应的3种三原色（RGB）。这里引入一个概念叫做<strong>channel</strong>。而与之对应的，filter的结构也由原来的3<br>x3变成了3x3x3，最后这个3对应的就是channel。然后每个filter跟原图做内积后（立方体的内积，也是对应位置的元素乘积加和），得到一个4x4xN的feature map，N为filter的个数。<br><img src="/images/pasted-27.png" alt="upload successful"></p>
<p><strong>那么为什么说Convolution是Fully Connected Neural Network的简化版呢？</strong></p>
<p>想象一下，原先每张6x6的黑白图片，拉平了就是一个有36个特征的向量，这个向量作为Fully Connected Neural Network的输入，那么按照全连接神经网络的结构，接下来就是0-n个隐层，然后就是输出层了。那么当我们在做Convolution的时候，每一个filter跟原图按设置好的stride去平移做内积，这个filter里对应的值，其实就相当于全连接神经网络里的每个weight了。那么从CNN的结构里可以看出，只有在跟filter做内积的元素才有对应的weight，其它没有在做内积的元素的weight都为0，并且这一组weight随着filter的平移做内积，其实是一样的，因此真正需要训练的weight的个数，就是filter里的size，这样就大大减少了全连接神经网络的参数个数了。</p>
<p>参考下图：<br><img src="/images/pasted-28.png" alt="upload successful"></p>
<h3 id="CNN-Pooling-池化"><a href="#CNN-Pooling-池化" class="headerlink" title="CNN-Pooling(池化)"></a>CNN-Pooling(池化)</h3><p>做Pooling，其实就是实现<strong>设计思路3</strong>的过程。在做完Convolution之后，我们得到了一个feature map(每个filter会对应一层)，然后针对每一层，通过某种group方式将元素分组，然后在每个分组内，按一定的方法去筛选元素（比如选择每个分组内的最大值，那么就是max pooling，比如选取一个平均值，那就是average pooling），然后就得到了一个新的“缩放后的图片”（这个“图片”的channel数量取决于filter的个数）。</p>
<p><strong>注意：在做Pooling的时候，不需要太过纠结于到底是用max pooling还是average pooling，因为完全可用i两者都用，且每一组在筛选时并不一定只筛选1个元素，完全可以先选一个最大值，再选一个平均值</strong></p>
<p>参考如下：<br><img src="/images/pasted-29.png" alt="upload successful"></p>
<h3 id="CNN-Flatten"><a href="#CNN-Flatten" class="headerlink" title="CNN-Flatten"></a>CNN-Flatten</h3><p>当一张图片输入，经过多个Convolution和Pooling层之后，输出的“图片”如果足够小了，那就可以做flatten，即把每个channel的元素拉直，作为输入丢到一个新的全连接神经网络里就行了。</p>
<p>参考如下：<br><img src="/images/pasted-30.png" alt="upload successful">Fu</p>
<h3 id="Fully-Connected-Neural-Network"><a href="#Fully-Connected-Neural-Network" class="headerlink" title="Fully Connected Neural Network"></a>Fully Connected Neural Network</h3><p>这里就是以flatten后的值作为输入，应用一个普通的全连接神经网络结构即可。只需注意损失函数、激活函数的选择。</p>
<h3 id="常见的CNN-Model"><a href="#常见的CNN-Model" class="headerlink" title="常见的CNN Model"></a>常见的CNN Model</h3><ul>
<li>LeNet，1986</li>
<li>AlexNet，2012</li>
<li>GoogleNet，2014</li>
<li>VGG，2014</li>
<li>Deep Residual Learning，2015</li>
</ul>
<h4 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h4><p>LeNet-5的filter都是5*5的，stride=1。LeNet-5用于手写体字符识别的非常高效的卷积神经网络。下面是经典的LeNet网络结构图<br><img src="/images/pasted-34.png" alt="upload successful"></p>
<ul>
<li>INPUT层-输入层：输入图像的尺寸统一归一化为32*32<ul>
<li><strong>注意：输入层不算网络层次结构之一</strong></li>
</ul>
</li>
<li><p>C1层-卷积层</p>
<ul>
<li>输入大小：32*32</li>
<li>卷积核大小(filter)：5*5</li>
<li>卷积核种类：6</li>
<li>输出的feature map大小：28*28，(32-5+1=28)，channel是6（filter个数）</li>
<li>神经元数量：28*28*6</li>
<li>可训练参数：(5*5+1)*6，每个filter是5*5个参数，加上一个bias</li>
<li><p>连接数：(5*5+1)*6*28*28，注意这里计算连接数的时候把bias的也加上了，可以理解为工程上实现需要，理论上是5*5*6*28*28</p>
<p><strong>说明：</strong>输入32*32的图片，第一次做卷积，通过6个5*5的filter，strade=1，得到6个28*28的C1 feature map。需要训练的参数个数就是(5*5+1)*6=156，其中+1是指每个filter对应的1个bias。那么很显然连接数就是156*28*28=122304个了。虽然连接数很多，但其实因为可训练参数只有156个，所以大大提高了训练效率。</p>
</li>
</ul>
</li>
<li><p>S2层-池化层(下采样层)</p>
<ul>
<li>输入大小：28*28</li>
<li>采样区域：2*2</li>
<li>采样方式：采样出来的元素相加，乘以一个weight，加上一个bias，通过sigmoid输出。</li>
<li>采样种类：6</li>
<li>输出的feature map大小：14*14，28/2=14，channel是6，池化不改变channel</li>
<li>可训练参数：(2*2+1)*6=30</li>
<li><p>连接数：(2*2+1)*6*14*14</p>
<p><strong>说明：</strong>卷积之后就是池化，现在是按照2*2的大小对C1 feature map的元素做group，每个group是4分元素，然后将4个元素加和，再乘以一个权重，再加上一个偏置，然后再通过sigmoid输出结果，最终得到6个14*14的 feature map。那么我们可以算出，连接数就是(2*2+1)*6*14*14=5880个。可训练参数个数是(2*2+1)*6=30个。</p>
<p>这里可能对采样种类和采样方式有点疑问。C1的feature map是有6个channel，每个channel的size是28*28，采样时就会对每一个channel进行采样，采样方式是一样的，都是用2*2的核去分组，然后每个分组的4个元素加和乘以weight再加上bias，然后通过sigmoid输出。但是每一个channel对应的weight和bias是不同的，因此这里说采样种类有6种。</p>
</li>
</ul>
</li>
<li><p>C3层-卷积层</p>
<ul>
<li>输入大小：<strong>S2中输出的不同channel的feature map的一种组合，那大小就是14*14</strong></li>
<li>卷积核大小：5*5，注意大小主要是指size，没有算上channel，算上channel的话应该是5*5*6</li>
<li>卷积核种类：16</li>
<li>输出的feature map大小：10*10，14-5+1=10，channel是16（filter个数）</li>
<li>可训练参数：(5*5*3+1)*6+(5*5*4+1)*6+(5*5*4+1)*3+(5*5*6+1)*1=1516</li>
<li><p>连接数：1516*10*10=151600</p>
<p><strong>说明：</strong>在第一次池化后接着做第二次卷积。此时用了16个5*5的卷积核，因此C3的输出就是16个10*10的feature map。<strong>C3在选择输入时做了一个非常规操作：将S2输出的不同channel的feature map做一些组合。</strong>用这些不同的组合再去跟C3的filter做内积。</p>
<p>举个例子：S2的feature map按channel分为第0，1，2，3，4，5个。现在C3有16个filter分别为第0，1，2…15个。在做卷积时，将S2的不同channel的feature map做一个组合，同一个组合使用一个filter做内积，最后一个filter用S2所有channel的feature map做输入。</p>
<p>具体见下图，其中横轴的0-15对应16个filter，纵轴表示S2输出的6个channel的feature map，X表示做内积。也就是说，filter0-5，分别跟相邻的3个channel的feature map组合后(012，123，234，345，450，501)做内积，filter6-11分别跟相邻的4个channel的feature map组合后(0123，1234，2345，3450，4501，5012)做内积，filter12-14分别跟不相邻的4个channel的feature map组合后(0134，1245，2350)做内积，最后filter15跟所有channel的feature map组合后做内积。最后得到10*10大小，channel=16的feature map作为输出。<br><img src="/images/pasted-32.png" alt="upload successful"></p>
</li>
</ul>
</li>
<li><p>S4层-池化层（下采样层）</p>
<ul>
<li>输入大小：10*10</li>
<li>采样区域：2*2</li>
<li>采样方式：采样出来的元素相加，乘以一个weight，加上一个bias，通过sigmoid输出。</li>
<li>采样种类：16</li>
<li>输出的feature map大小：5*6，10/2=14，channel是16，池化不改变channel</li>
<li>可训练参数：(2*2+1)*16=80</li>
<li><p>连接数：(2*2+1)*16*5*5=2000</p>
<p><strong>说明：可参考S2池化层，主要区别就是channel不同</strong></p>
</li>
</ul>
</li>
<li><p>C5层-卷积层</p>
<ul>
<li>输入大小：<strong>S4中输出的所有channel的feature map，大小是5*5</strong></li>
<li>卷积核大小：5*5，注意大小主要是指size，没有算上channel，算上channel的话应该是5*5*6</li>
<li>卷积核种类：120</li>
<li>输出的feature map大小：1*1，5-5+1=1，channel是120（filter个数）</li>
<li>可训练参数：(5*5*16+1)*120=48120</li>
<li><p>连接数：48120*1*1=48120</p>
<p><strong>说明：S4输出的feature map大小为5*5，此时根filter的大小相同，因此C5输出feature map的大小为1*1。C5层在做卷积的时候，用了120个filter，每个filter都跟S4的所有feature map做内积，因此可训练参数和连接数都为(5*5*16+1)*120=48120</strong></p>
</li>
</ul>
</li>
<li><p>F6层-Flatten</p>
<ul>
<li>输入大小：<strong>C5中输出的120个1*1的feature map</strong></li>
<li>输出的feature map大小：1*1，channel=84，这里的84取决于输出层的设计</li>
<li>可训练参数：(1*1*120+1)*84=10164</li>
<li><p>连接数：10164*1*1=10164</p>
<p><strong>说明：F6层是做Flatten的，和C5层的输出层做全连接，即输入向量跟权重向量做内积后加上偏置，然后这个值输入sigmoid函数得到输出。权重向量取决于输出层的设计，比如此时是84维的，因此可训练参数和连接数都是(1*1*120+1)*84=10164</strong></p>
</li>
</ul>
</li>
<li><p>输出层</p>
<p>  输出层由欧式径向基函数（Euclidean Radial Basis Function）神经元组成，每个类别对应一个神经元，一共10类，故10个神经元，每个神经元都有84个输入。</p>
</li>
</ul>
<h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><p>LeNet主要用于手写数字的识别，比如邮局会使用，正确率达到了98%。2012年出现了AlexNet，赢得了2012届图像识别大赛的冠军，使得CNN成为在图像分类上的核心算法模型。下面来具体描述下AlexNet的网络结构。</p>
<p><img src="/images/pasted-35.png" alt="upload successful"></p>
<ul>
<li><p>模块1<br><img src="/images/pasted-36.png" alt="upload successful"></p>
<p>  <strong>说明：原始图片227*227*3作为输入，filter为11*11，channel=3，stride=4，有96个filter，因此做Conv1输出的feature map为55*55，channel=96。然后对这些输出的feature map通过激活函数ReLU1，把输出的值的范围控制在[0,正无穷]。接着做池化Pool1，池化层的kernel_size=3，stride=2，输出27*27，channel=96的feature map，然后对这些feature map做Batch Normalization Norm1，local_size=5，注意，BN是对每一个channel的feature map分别做标准化。</strong></p>
</li>
</ul>
<h2 id="CNN改进版-R-CNN-amp-Fast-R-CNN-amp-Faster-R-CNN"><a href="#CNN改进版-R-CNN-amp-Fast-R-CNN-amp-Faster-R-CNN" class="headerlink" title="CNN改进版 R-CNN &amp; Fast R-CNN &amp; Faster R-CNN"></a>CNN改进版 R-CNN &amp; Fast R-CNN &amp; Faster R-CNN</h2><p>CNN帮我们解决了图像识别问题，然而在实际的图像任务中，图像识别仅仅是开始。<br><img src="/images/pasted-31.png" alt="upload successful"><br>上图反映了图像任务的几个阶段：</p>
<ul>
<li>图像识别(Classification)：单对象分类问题</li>
<li>图像识别+定位(Classification+Localization)：单对象分类+单对象定位问题</li>
<li>物体检测(Object Detection)：多对象分类+多对象定位问题</li>
<li>实例分割(Instance Segmentation)：多对象分类+多对象分割问题</li>
</ul>
<h3 id="设计思路-amp-网络结构-1"><a href="#设计思路-amp-网络结构-1" class="headerlink" title="设计思路&amp;网络结构"></a>设计思路&amp;网络结构</h3><p>经典的CNN已经可以做到单对象分类，那么怎么解决单对象定位问题呢？我们可以通过一个框去框出一个对象，用于对象的定位。用4个值去表示一个框(x,y,w,h)，x、y为框的一个顶点（左上角）坐标，w代表宽度，h代表高度，那么通过这4个值就可以描述一个框了。那么这4个值怎么获得呢？</p>
<p><strong>思路1：看做回归问题</strong>，预测出(x,y,w,h)的值，从而得出方框的位置。</p>
<h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li>《Convolutional Neural Network》：<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html" target="_blank" rel="noopener">http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html</a></li>
<li>《网络解析（一）：LeNet-5详解》：<a href="http://cuijiahua.com/blog/2018/01/dl_3.html" target="_blank" rel="noopener">http://cuijiahua.com/blog/2018/01/dl_3.html</a></li>
<li>《AlexNet详解3》：<a href="https://www.cnblogs.com/alexanderkun/p/6918045.html" target="_blank" rel="noopener">https://www.cnblogs.com/alexanderkun/p/6918045.html</a></li>
<li>《卷积神经网络CNN（2）—— BN(Batch Normalization) 原理与使用过程详解》：<a href="https://blog.csdn.net/fate_fjh/article/details/53375881" target="_blank" rel="noopener">https://blog.csdn.net/fate_fjh/article/details/53375881</a></li>
<li>《基于深度学习的目标检测技术演进》：<a href="https://www.cnblogs.com/skyfsm/p/6806246.html" target="_blank" rel="noopener">https://www.cnblogs.com/skyfsm/p/6806246.html</a></li>
</ul>
</div><div class="tags"><a href="/tags/CNN/">CNN</a></div><div class="post-nav"><a class="pre" href="/2018/11/05/20181029-20181104/">20181029-20181104</a><a class="next" href="/2018/07/27/奥林匹斯Olympus/">奥林匹斯Olympus</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://wulouzi.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/DATABASE/">DATABASE</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Flink/">Flink</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LITERATURE/">LITERATURE</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/周报/">周报</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据中台/">数据中台</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/翻墙/">翻墙</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/数据中台/" style="font-size: 15px;">数据中台</a> <a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/仓央嘉措/" style="font-size: 15px;">仓央嘉措</a> <a href="/tags/杂/" style="font-size: 15px;">杂</a> <a href="/tags/CNN/" style="font-size: 15px;">CNN</a> <a href="/tags/奥林匹斯/" style="font-size: 15px;">奥林匹斯</a> <a href="/tags/降维/" style="font-size: 15px;">降维</a> <a href="/tags/MYSQL/" style="font-size: 15px;">MYSQL</a> <a href="/tags/vps-ss/" style="font-size: 15px;">vps+ss</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/08/12/Flink快速部署项目-WordCount/">Flink快速部署项目+WordCount</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/05/20181029-20181104/">20181029-20181104</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/18/CNN/">CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/27/奥林匹斯Olympus/">奥林匹斯Olympus</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/07/机器学习之降维/">机器学习之降维</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/23/来自曾经仰慕过的人/">悦读·悦自己</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/10/地空/">地空</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/10/Vultr-VPS搭建SS-ShadowSocks-教程/">Vultr VPS搭建SS(ShadowSocks)教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/10/MYSQL索引原理及优化/">MYSQL索引原理及优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/10/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://flarywu.github.io/" title="flary's blog" target="_blank">flary's blog</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">逐浪钱塘.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>